{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fp9hbokQIxWW"
   },
   "source": [
    "# Permuted and Split MNIST: a Deep Continual Learning Example in PyTorch\n",
    "\n",
    "In this brief demo we will showcase two common *Continual Learning* benchmark often used to introduce the problem and start prototyping possible computational strategies to solve it. We will use bare Python, Numpy and *PyTorch*. In order to construct these benchmarks we will start from the the standard MNIST dataset (LeCun, 1998)!\n",
    "\n",
    "We will start with learning over the standard *MNIST* benchmark, then we will move in the actual continual learning setting  with the *Permuted MNIST* and *Split MNIST*  benchmarks. Let's have some fun! :-)\n",
    "\n",
    "\n",
    "---\n",
    "**Connecting a local runtime**\n",
    "\n",
    "In case resources are not enough for you (no GPU for example), you can always connect another [local runtime](https://research.google.com/colaboratory/local-runtimes.html) or to a [runtime on a Google Compute Engine instance](https://research.google.com/colaboratory/local-runtimes.html).\n",
    "\n",
    "This notebook has been designed to run fast enough on simple CPUs so you shouldn't find any trouble here, using a free *hosted account*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z6RUp96FLuMd"
   },
   "source": [
    "# Google Colaboratory\n",
    "\n",
    "First of all, take a moment to look around and discover Google Colab if you haven't before! You can run the commands below to understand how much resources you're using and are still available. Then consider also that you can also connect your Google Drive for additional space or for easily loading your own files.\n",
    "\n",
    "You can always reset the entire VM with \"*Runtime > Reset all runtime*\" in case of difficulty. Make also sure you're using the GPU or TPU in the same  tab (\"*Runtime > Change runtime type*\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pPViRmMBqbJ2",
    "outputId": "da8e256d-9a74-43c4-aae6-a4ee45d43ab0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\n",
      "Mem:          15925        3688        6701          54        5534       11855\n",
      "Swap:         30516           0       30516\n",
      "Filesystem      Size  Used Avail Use% Mounted on\n",
      "udev            7.8G     0  7.8G   0% /dev\n",
      "tmpfs           1.6G  2.0M  1.6G   1% /run\n",
      "/dev/sdb5        46G   20G   24G  47% /\n",
      "tmpfs           7.8G  800K  7.8G   1% /dev/shm\n",
      "tmpfs           5.0M  4.0K  5.0M   1% /run/lock\n",
      "tmpfs           7.8G     0  7.8G   0% /sys/fs/cgroup\n",
      "/dev/loop0      234M  234M     0 100% /snap/cherrytree/59\n",
      "/dev/loop1      304M  304M     0 100% /snap/wine-platform-5-stable/18\n",
      "/dev/loop2      211M  211M     0 100% /snap/eclipse/48\n",
      "/dev/loop3      165M  165M     0 100% /snap/gnome-3-28-1804/161\n",
      "/dev/loop4       20M   20M     0 100% /snap/photoscape/68\n",
      "/dev/loop5      2.7M  2.7M     0 100% /snap/gnome-system-monitor/178\n",
      "/dev/loop6      768K  768K     0 100% /snap/gnome-characters/761\n",
      "/dev/loop7      640K  640K     0 100% /snap/gnome-logs/112\n",
      "/dev/loop8       92M   92M     0 100% /snap/gtk-common-themes/1535\n",
      "/dev/loop9      256K  256K     0 100% /snap/gtk2-common-themes/13\n",
      "/dev/loop10     2.5M  2.5M     0 100% /snap/gnome-calculator/884\n",
      "/dev/loop11      71M   71M     0 100% /snap/core22/188\n",
      "/dev/loop12     115M  115M     0 100% /snap/core/13741\n",
      "/dev/loop13     224M  224M     0 100% /snap/code/108\n",
      "/dev/loop14     190M  190M     0 100% /snap/audacity/1032\n",
      "/dev/loop18     401M  401M     0 100% /snap/gnome-3-38-2004/112\n",
      "/dev/loop15     296M  296M     0 100% /snap/vlc/2344\n",
      "/dev/loop16     347M  347M     0 100% /snap/wine-platform-runtime/316\n",
      "/dev/loop17      64M   64M     0 100% /snap/core20/1623\n",
      "/dev/loop19      71M   71M     0 100% /snap/core22/275\n",
      "/dev/loop21     250M  250M     0 100% /snap/audacity/1051\n",
      "/dev/loop28     219M  219M     0 100% /snap/gnome-3-34-1804/77\n",
      "/dev/loop23     2.7M  2.7M     0 100% /snap/gnome-calculator/920\n",
      "/dev/loop25      56M   56M     0 100% /snap/core18/2566\n",
      "/dev/loop20     124M  124M     0 100% /snap/cherrytree/58\n",
      "/dev/loop22     347M  347M     0 100% /snap/gnome-3-38-2004/115\n",
      "/dev/loop26     143M  143M     0 100% /snap/chromium/2105\n",
      "/dev/loop27     315M  315M     0 100% /snap/eclipse/61\n",
      "/dev/loop29      82M   82M     0 100% /snap/gtk-common-themes/1534\n",
      "/dev/loop24     224M  224M     0 100% /snap/code/107\n",
      "/dev/loop31      56M   56M     0 100% /snap/core18/2560\n",
      "/dev/loop30      62M   62M     0 100% /snap/core20/1611\n",
      "/dev/loop33     161M  161M     0 100% /snap/gnome-3-28-1804/116\n",
      "/dev/loop32     128K  128K     0 100% /snap/bare/5\n",
      "/dev/loop36     640K  640K     0 100% /snap/gnome-logs/106\n",
      "/dev/loop35     768K  768K     0 100% /snap/gnome-characters/741\n",
      "/dev/loop37     2.7M  2.7M     0 100% /snap/gnome-system-monitor/174\n",
      "/dev/loop38     114M  114M     0 100% /snap/core/13425\n",
      "/dev/loop34     143M  143M     0 100% /snap/chromium/2082\n",
      "/dev/loop39     415M  415M     0 100% /snap/gnome-42-2204/29\n",
      "/dev/sdb7       405G  295G   90G  77% /home\n",
      "tmpfs           1.6G   84K  1.6G   1% /run/user/1000\n",
      "Mon Sep 26 11:11:04 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 390.154                Driver Version: 390.154                   |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GT 755M     Off  | 00000000:01:00.0 N/A |                  N/A |\n",
      "| N/A   61C    P0    N/A /  N/A |    160MiB /  2002MiB |     N/A      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0                    Not Supported                                       |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!free -m\n",
    "!df -h\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jt_PxOYPmxp_"
   },
   "source": [
    "**Questions to explore:**\n",
    "\n",
    "*   How to connect your Google Drive with Google Colab?\n",
    "*   How to import a new notebook and save it to your GDrive?\n",
    "*   How to use files which are contained in your GDrive?\n",
    "\n",
    "Some tips here: https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i74kZQufNv5d"
   },
   "source": [
    "Ok, if you are on Colab PyTorch is already installed! Let's import it and see if it can find the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hv7FUJ2Wrd_l",
    "outputId": "7374c015-0482-4714-8ed6-24cc184bbe69"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JuSqVkPnN7iT"
   },
   "source": [
    "That's great, let us import then a few libraries, which we'll be using during this tutorial!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "w7AxhUWe68vT"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rv89m9nBPXSh"
   },
   "source": [
    "# MNIST: Digits recognition with PyTorch \n",
    "\n",
    "All right, let's start then making sure we all know the basics! Let's recognize the ten handwritten digits learning from 60.000, 28x28 grayscale images.\n",
    "For simplicity let's import a loading script we have already developed inside the **Continual AI Colab** repository:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yKWbcnh474X3",
    "outputId": "ff65ad14-f1db-4b5e-c1f0-242110813fa8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'continualai/colab' already exists and is not an empty directory.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ContinualAI/colab.git continualai/colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x3BFVukM_y8i",
    "outputId": "e3c9a181-6cbd-44e1-d681-beb090625e31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded!\n"
     ]
    }
   ],
   "source": [
    "from continualai.colab.scripts import mnist\n",
    "mnist.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6jIk6-G6AhWi",
    "outputId": "f6114ff9-6bd6-4c01-b4fb-7f164dc6a5de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train dim and type:  (60000, 1, 28, 28) float32\n",
      "t_train dim and type:  (60000,) uint8\n",
      "x_test dim and type:  (10000, 1, 28, 28) float32\n",
      "t_test dim and type:  (10000,) uint8\n"
     ]
    }
   ],
   "source": [
    "x_train, t_train, x_test, t_test = mnist.load()\n",
    "\n",
    "print(\"x_train dim and type: \", x_train.shape, x_train.dtype)\n",
    "print(\"t_train dim and type: \", t_train.shape, t_train.dtype)\n",
    "print(\"x_test dim and type: \", x_test.shape, x_test.dtype)\n",
    "print(\"t_test dim and type: \", t_test.shape, t_test.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XEWG2PmbVvb7"
   },
   "source": [
    "Let's take a look at the actual images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "RyIuYAw8AuO6",
    "outputId": "07106299-84cf-4cef-b9ba-802d370a6fe9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, axarr = plt.subplots(2,2)\n",
    "axarr[0,0].imshow(x_train[1, 0], cmap=\"gray\")\n",
    "axarr[0,1].imshow(x_train[2, 0], cmap=\"gray\")\n",
    "axarr[1,0].imshow(x_train[3, 0], cmap=\"gray\")\n",
    "axarr[1,1].imshow(x_train[4, 0], cmap=\"gray\")\n",
    "np.vectorize(lambda ax:ax.axis('off'))(axarr);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "baEsU4PGXsgS"
   },
   "source": [
    "Good! Let's now set up a few general setting before using torch..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ztZAPQNXZ4ll"
   },
   "outputs": [],
   "source": [
    "# switch to False to use CPU\n",
    "use_cuda = True\n",
    "\n",
    "use_cuda = use_cuda and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\");\n",
    "torch.manual_seed(1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Ek0mErIac6n"
   },
   "source": [
    "... and define our first conv-net! We will use 3 layers of convolutions and two fully connected layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ONMdybG4Be0z"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p9S6a-MlYAsu"
   },
   "source": [
    "Then we can write the *train* and *test* functions. Note that for simplicity here we are not using PyTorch [Data Loaders](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html) but this is not recommended for efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "HGJJfXhJB-zk"
   },
   "outputs": [],
   "source": [
    "def train(model, device, x_train, t_train, optimizer, epoch):\n",
    "    model.train()\n",
    "    \n",
    "    for start in range(0, len(t_train)-1, 256):\n",
    "      end = start + 256\n",
    "      x, y = torch.from_numpy(x_train[start:end]), torch.from_numpy(t_train[start:end]).long()\n",
    "      x, y = x.to(device), y.to(device)\n",
    "      \n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      output = model(x)\n",
    "      loss = F.cross_entropy(output, y)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      #print(loss.item())\n",
    "    print('Train Epoch: {} \\tLoss: {:.6f}'.format(epoch, loss.item()))\n",
    "\n",
    "def test(model, device, x_test, t_test):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for start in range(0, len(t_test)-1, 256):\n",
    "      end = start + 256\n",
    "      with torch.no_grad():\n",
    "        x, y = torch.from_numpy(x_test[start:end]), torch.from_numpy(t_test[start:end]).long()\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        output = model(x)\n",
    "        test_loss += F.cross_entropy(output, y).item() # sum up batch loss\n",
    "        pred = output.max(1, keepdim=True)[1] # get the index of the max logit\n",
    "        correct += pred.eq(y.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(t_test)\n",
    "    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(t_test),\n",
    "        100. * correct / len(t_test)))\n",
    "    return 100. * correct / len(t_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IxIISdDPaqb9"
   },
   "source": [
    "Then we are ready to instantiate our model and start the training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "1cJURe0JCFh8"
   },
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BlhVt8vylpUv",
    "outputId": "5ffc387f-3083-4b24-cf78-861577f6e424"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 \tLoss: 0.642091\n",
      "Test set: Average loss: 0.0013, Accuracy: 9018/10000 (90%)\n",
      "\n",
      "Train Epoch: 2 \tLoss: 0.395983\n",
      "Test set: Average loss: 0.0007, Accuracy: 9433/10000 (94%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 3):\n",
    "  train(model, device, x_train, t_train, optimizer, epoch)\n",
    "  test(model, device, x_test, t_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7qwh4T5Va86-"
   },
   "source": [
    "Wow! 94% accuracy in such a short time. \n",
    "\n",
    "**Questions to explore:**\n",
    "\n",
    "*   Can you find a better parametrization to improve the final accuracy?\n",
    "*   Can you change the network architecture to improve the final accuracy?\n",
    "*   Can you achieve the same performances with a smaller architecture?\n",
    "*   What's the difference in accuracy if you change convolutions with fully connected layers?\n",
    "\n",
    "Some tips here: http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#4d4e495354"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2dn-5gOGq08g"
   },
   "source": [
    "# Permuted MNIST\n",
    "\n",
    "But what if now we want we the same model being able to solve a new task we encounter over time like a permuted version of the same MNIST? Let's define our custom function to permute it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "6Xq_4UvjgXPQ"
   },
   "outputs": [],
   "source": [
    "def permute_mnist(mnist, seed):\n",
    "    \"\"\" Given the training set, permute pixels of each img the same way. \"\"\"\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    print(\"starting permutation...\")\n",
    "    h = w = 28\n",
    "    perm_inds = list(range(h*w))\n",
    "    np.random.shuffle(perm_inds)\n",
    "    # print(perm_inds)\n",
    "    perm_mnist = []\n",
    "    for set in mnist:\n",
    "        num_img = set.shape[0]\n",
    "        flat_set = set.reshape(num_img, w * h)\n",
    "        perm_mnist.append(flat_set[:, perm_inds].reshape(num_img, 1, w, h))\n",
    "    print(\"done.\")\n",
    "    return perm_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4xG5LFwLgkpu",
    "outputId": "398afb1c-4dea-421d-cab0-66b7587d49c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting permutation...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "x_train2, x_test2 = permute_mnist([x_train, x_test], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183
    },
    "id": "LYBa_Gedh_do",
    "outputId": "183cca92-ea04-414c-e77e-942fef2162bd"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, axarr = plt.subplots(1,2)\n",
    "axarr[0].imshow(x_train[1, 0], cmap=\"gray\")\n",
    "axarr[1].imshow(x_train2[2, 0], cmap=\"gray\")\n",
    "np.vectorize(lambda ax:ax.axis('off'))(axarr);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46wHcbNAchH-"
   },
   "source": [
    "Amazing. Now let's see how our pre-trained model is working on both the original and the permuted MNIST dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sxusb8s3itli",
    "outputId": "e9af3f91-2358-4fc4-c5a5-d209d171dd71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on the first task:\n",
      "Test set: Average loss: 0.0007, Accuracy: 9433/10000 (94%)\n",
      "\n",
      "Testing on the second task:\n",
      "Test set: Average loss: 0.0108, Accuracy: 1072/10000 (11%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing on the first task:\")\n",
    "test(model, device, x_test, t_test)\n",
    "\n",
    "print(\"Testing on the second task:\")\n",
    "test(model, device, x_test2, t_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0pHMg4G_dHFY"
   },
   "source": [
    "Mmmh... that's pretty bad, our model cannot generalize to this apparently very different new task! Well, we can just finetune our model using the new permuted training set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J5PtR8Gqib00",
    "outputId": "5886261f-3a1a-44b9-dc84-85e9e1e89cd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 \tLoss: 1.591063\n",
      "Test set: Average loss: 0.0032, Accuracy: 7367/10000 (74%)\n",
      "\n",
      "Train Epoch: 2 \tLoss: 1.264862\n",
      "Test set: Average loss: 0.0022, Accuracy: 8273/10000 (83%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 3):\n",
    "  train(model, device, x_train2, t_train, optimizer, epoch)\n",
    "  test(model, device, x_test2, t_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ML7Evzb9jPAZ",
    "outputId": "e419bca6-e07f-4a3c-d7fe-2cb64e950d2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on the first task:\n",
      "Test set: Average loss: 0.0224, Accuracy: 2456/10000 (25%)\n",
      "\n",
      "Testing on the second task:\n",
      "Test set: Average loss: 0.0022, Accuracy: 8273/10000 (83%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing on the first task:\")\n",
    "test(model, device, x_test, t_test)\n",
    "\n",
    "print(\"Testing on the second task:\")\n",
    "test(model, device, x_test2, t_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0UZ6FBuHdm7N"
   },
   "source": [
    "This is very annoying! Now we are not able to solve the original MNIST task anymore! :-( This is the phenomenon known in literature as **Catastrophic Forgetting**! In the following section we well compare three basic baselines for continual learning (and trying to not forget!)\n",
    "\n",
    "**Questions to explore:**\n",
    "\n",
    "*   When the permuted MNIST benchmark has been firstly introduced? \n",
    "*   Can simple Dropout and Regularization techniques reduce forgetting?\n",
    "*   In the permuted MNIST task, do convolutions still help increasing the accuracy?\n",
    "\n",
    "Some tips here: https://papers.nips.cc/paper/5059-compete-to-compute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9rUgLpUakTy6"
   },
   "source": [
    "## Naive Continual Learning by Finetuning\n",
    "\n",
    "Let us now try to learn continuously with just finetuning and see what we get.\n",
    "We will build a 3-tasks Permuted MNIST benchmark. Finally we will plot our accuracy results at the end of every task. Let's start by defining our 3 tasks with the function we have already introduced before:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yu0T_V24joGY",
    "outputId": "0799a0e1-7242-408e-f107-fb45554b30cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting permutation...\n",
      "done.\n",
      "starting permutation...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "# task 1\n",
    "task_1 = [(x_train, t_train), (x_test, t_test)]\n",
    "\n",
    "# task 2\n",
    "x_train2, x_test2 = permute_mnist([x_train, x_test], 1)\n",
    "task_2 = [(x_train2, t_train), (x_test2, t_test)]\n",
    "\n",
    "# task 3\n",
    "x_train3, x_test3 = permute_mnist([x_train, x_test], 2)\n",
    "task_3 = [(x_train3, t_train), (x_test3, t_test)]\n",
    "\n",
    "# task list\n",
    "tasks = [task_1, task_2, task_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "gzFEA5F8pI_O"
   },
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dLU6KdIbnLMN",
    "outputId": "ff46575f-3f38-4a53-bd0c-db68a034bfb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on task:  0\n",
      "Train Epoch: 1 \tLoss: 0.628392\n",
      "Testing on task:  0\n",
      "Test set: Average loss: 0.0012, Accuracy: 9034/10000 (90%)\n",
      "\n",
      "Testing on task:  1\n",
      "Test set: Average loss: 0.0115, Accuracy: 568/10000 (6%)\n",
      "\n",
      "Testing on task:  2\n",
      "Test set: Average loss: 0.0102, Accuracy: 1127/10000 (11%)\n",
      "\n",
      "Avg acc:  35.763333333333335\n",
      "Training on task:  1\n",
      "Train Epoch: 1 \tLoss: 1.642073\n",
      "Testing on task:  0\n",
      "Test set: Average loss: 0.0221, Accuracy: 1784/10000 (18%)\n",
      "\n",
      "Testing on task:  1\n",
      "Test set: Average loss: 0.0045, Accuracy: 6782/10000 (68%)\n",
      "\n",
      "Testing on task:  2\n",
      "Test set: Average loss: 0.0117, Accuracy: 1262/10000 (13%)\n",
      "\n",
      "Avg acc:  32.76\n",
      "Training on task:  2\n",
      "Train Epoch: 1 \tLoss: 1.717480\n",
      "Testing on task:  0\n",
      "Test set: Average loss: 0.0223, Accuracy: 1480/10000 (15%)\n",
      "\n",
      "Testing on task:  1\n",
      "Test set: Average loss: 0.0080, Accuracy: 2894/10000 (29%)\n",
      "\n",
      "Testing on task:  2\n",
      "Test set: Average loss: 0.0043, Accuracy: 6819/10000 (68%)\n",
      "\n",
      "Avg acc:  37.31\n"
     ]
    }
   ],
   "source": [
    "naive_accs = []\n",
    "\n",
    "for id, task in enumerate(tasks):\n",
    "  avg_acc = 0\n",
    "  print(\"Training on task: \", id)\n",
    "  \n",
    "  (x_train, t_train), _ = task\n",
    "  \n",
    "  for epoch in range(1, 2):\n",
    "    train(model, device, x_train, t_train, optimizer, epoch)\n",
    "    \n",
    "  for id_test, task in enumerate(tasks):\n",
    "    print(\"Testing on task: \", id_test)\n",
    "    _, (x_test, t_test) = task\n",
    "    acc = test(model, device, x_test, t_test)\n",
    "    avg_acc = avg_acc + acc \n",
    "  \n",
    "  naive_accs.append(avg_acc / 3)\n",
    "  print(\"Avg acc: \", avg_acc / 3)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ANJfdFD3s0oT"
   },
   "source": [
    "**Questions to explore:**\n",
    "\n",
    "*   Does the order of the tasks effect the final results? \n",
    "\n",
    "Some tips here: http://proceedings.mlr.press/v78/lomonaco17a/lomonaco17a.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lCK0EYT-pJa8"
   },
   "source": [
    "## Cumulative Strategy\n",
    "\n",
    "Another simple CL idea is to carry on *all* or *part* of the previously encountered examples (of the previous tasks), shuffling them with the data of the current task. Using *all* the past data is near to the optimal performance we can desire at the end of the task sequence but at the expense of much bigger memory usage.\n",
    "\n",
    "Let's start by defining a function to shuffle our data:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "FdWpT2jhfu3o"
   },
   "outputs": [],
   "source": [
    "def shuffle_in_unison(dataset, seed, in_place=False):\n",
    "    \"\"\" Shuffle two (or more) list in unison. \"\"\"\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    rng_state = np.random.get_state()\n",
    "    new_dataset = []\n",
    "    for x in dataset:\n",
    "        if in_place:\n",
    "            np.random.shuffle(x)\n",
    "        else:\n",
    "            new_dataset.append(np.random.permutation(x))\n",
    "        np.random.set_state(rng_state)\n",
    "\n",
    "    if not in_place:\n",
    "        return new_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "94hg1UrtqFmT"
   },
   "source": [
    "Now we can reset the model and optimizer and run our training over the tasks sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "62TY0Ajgbsgk"
   },
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y_No-qvDbuZi",
    "outputId": "4406de47-ca62-4a6d-a669-a03c4fe6875d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on task:  0\n",
      "Train Epoch: 1 \tLoss: 0.586831\n",
      "Testing on task:  0\n",
      "Test set: Average loss: 0.0012, Accuracy: 9080/10000 (91%)\n",
      "\n",
      "Testing on task:  1\n",
      "Test set: Average loss: 0.0111, Accuracy: 770/10000 (8%)\n",
      "\n",
      "Testing on task:  2\n",
      "Test set: Average loss: 0.0099, Accuracy: 1258/10000 (13%)\n",
      "\n",
      "Avg acc:  37.026666666666664\n",
      "Training on task:  1\n",
      "Train Epoch: 1 \tLoss: 0.836288\n",
      "Testing on task:  0\n",
      "Test set: Average loss: 0.0008, Accuracy: 9403/10000 (94%)\n",
      "\n",
      "Testing on task:  1\n",
      "Test set: Average loss: 0.0036, Accuracy: 7436/10000 (74%)\n",
      "\n",
      "Testing on task:  2\n",
      "Test set: Average loss: 0.0102, Accuracy: 1281/10000 (13%)\n",
      "\n",
      "Avg acc:  60.4\n",
      "Training on task:  2\n",
      "Train Epoch: 1 \tLoss: 0.674825\n",
      "Testing on task:  0\n",
      "Test set: Average loss: 0.0006, Accuracy: 9514/10000 (95%)\n",
      "\n",
      "Testing on task:  1\n",
      "Test set: Average loss: 0.0022, Accuracy: 8359/10000 (84%)\n",
      "\n",
      "Testing on task:  2\n",
      "Test set: Average loss: 0.0027, Accuracy: 8061/10000 (81%)\n",
      "\n",
      "Avg acc:  86.44666666666667\n"
     ]
    }
   ],
   "source": [
    "cumul_accs = []\n",
    "for id, task in enumerate(tasks):\n",
    "  avg_acc = 0\n",
    "  print(\"Training on task: \", id)\n",
    "  \n",
    "  (x_train, t_train), _ = task\n",
    "  \n",
    "  # for previous task\n",
    "  for i in range(id):\n",
    "    (past_x_train, past_t_train), _ = tasks[i]\n",
    "    x_train = np.concatenate((x_train, past_x_train))\n",
    "    t_train = np.concatenate((t_train, past_t_train))\n",
    "  \n",
    "  x_train, t_train = shuffle_in_unison([x_train, t_train], 0)\n",
    "  \n",
    "  for epoch in range(1, 2):\n",
    "    train(model, device, x_train, t_train, optimizer, epoch)\n",
    "    \n",
    "  for id_test, task in enumerate(tasks):\n",
    "    print(\"Testing on task: \", id_test)\n",
    "    _, (x_test, t_test) = task\n",
    "    acc = test(model, device, x_test, t_test)\n",
    "    avg_acc = avg_acc + acc\n",
    "   \n",
    "  print(\"Avg acc: \", avg_acc / 3)\n",
    "  cumul_accs.append(avg_acc/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jCna5k0DtN-X"
   },
   "source": [
    "**Questions to explore:**\n",
    "\n",
    "*   Can you find a way to reduce the number of examples of the previous tasks to maintain in memory? \n",
    "*   Can you find a good trade-off between memory overhead and final accuracy?\n",
    "*   Why is shuffling needed here?\n",
    "\n",
    "Some tips here: https://arxiv.org/abs/1809.05922"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RrbnV6OqW66y"
   },
   "source": [
    "## JointTraining Strategy\n",
    "\n",
    "While not a proper continual learning strategy, a commonly used baseline for continual learning is what's called \"JointTraining\" or \"offline strategy\", that is a multi-task training setting where all the data are seen at once hence simulating a static setting. This is often intended as a performance upper-bound for a continual learning problem.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "gq_bYiYQbHzq"
   },
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T7iwZCidbIqs",
    "outputId": "27da30f3-12cf-4153-950e-02c0416d14a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on all tasks together...\n",
      "Train Epoch: 1 \tLoss: 1.201041\n",
      "Train Epoch: 2 \tLoss: 0.687878\n",
      "Train Epoch: 3 \tLoss: 0.490674\n",
      "Testing on task:  0\n",
      "Test set: Average loss: 0.0007, Accuracy: 9449/10000 (94%)\n",
      "\n",
      "Testing on task:  1\n",
      "Test set: Average loss: 0.0016, Accuracy: 8835/10000 (88%)\n",
      "\n",
      "Testing on task:  2\n",
      "Test set: Average loss: 0.0017, Accuracy: 8805/10000 (88%)\n",
      "\n",
      "Avg acc:  90.29666666666667\n"
     ]
    }
   ],
   "source": [
    "offline_accs = []\n",
    "\n",
    "print(\"Training on all tasks together...\")\n",
    "avg_acc = 0\n",
    "(x_train, t_train), _ = tasks[0]\n",
    "  \n",
    "for i in range(1, len(tasks)):\n",
    "    (past_x_train, past_t_train), _ = tasks[i]\n",
    "    x_train = np.concatenate((x_train, past_x_train))\n",
    "    t_train = np.concatenate((t_train, past_t_train))\n",
    "  \n",
    "x_train, t_train = shuffle_in_unison([x_train, t_train], 0)\n",
    "\n",
    "for epoch in range(1, 4):\n",
    "    train(model, device, x_train, t_train, optimizer, epoch)\n",
    "    \n",
    "for id_test, task in enumerate(tasks):\n",
    "    print(\"Testing on task: \", id_test)\n",
    "    _, (x_test, t_test) = task\n",
    "    acc = test(model, device, x_test, t_test)\n",
    "    avg_acc = avg_acc + acc\n",
    "   \n",
    "print(\"Avg acc: \", avg_acc / 3)\n",
    "for i in range(len(tasks)):\n",
    "    offline_accs.append(avg_acc/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5B9b4cCgy0k_"
   },
   "source": [
    "**Questions to explore:**\n",
    "\n",
    "- Is the *JointTraining* strategy really an upper-bound for continual learning?\n",
    "- Can curriculum learning improve our final performace?\n",
    "\n",
    "Some tips here: https://arxiv.org/pdf/1904.03626.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o3SM7U5fwTqV"
   },
   "source": [
    "## Plot Results\n",
    "\n",
    "To conclude, let's summerize our results in a nice plot! :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "sIQEVVpDwPP5",
    "outputId": "571b14d3-ad29-445a-fb6e-44b2344392d8"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([1, 2, 3], naive_accs, '-o', label=\"Naive\")\n",
    "plt.plot([1, 2, 3], cumul_accs, '-o', label=\"Cumulative\")\n",
    "plt.plot([1, 2, 3], offline_accs, '-o', label=\"JointTraining\")\n",
    "plt.xlabel('Tasks Encountered', fontsize=14)\n",
    "plt.ylabel('Average Accuracy', fontsize=14)\n",
    "plt.title('CL Baselines Comparison on Permuted MNIST', fontsize=14);\n",
    "plt.xticks([1, 2, 3])\n",
    "plt.legend(prop={'size': 16});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9x1D3O7iunxS"
   },
   "source": [
    "**Questions to explore:**\n",
    "\n",
    "*   What's the difference in terms of memory utilization among the three methods? \n",
    "*   Can you plot a similar graph highlighting the memory increase over time?\n",
    "\n",
    "Some tips here: https://stackoverflow.com/questions/449560/how-do-i-determine-the-size-of-an-object-in-python/30316760"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5_wUBAosdjUe"
   },
   "source": [
    "# Split MNIST\n",
    "\n",
    "Split MNIST is just a split in different batches of the original MNIST data. You can do this definining a simple function such as the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "FiL1p163d5CJ"
   },
   "outputs": [],
   "source": [
    "def split_mnist(train_x, train_y, test_x, test_y, n_splits=5):\n",
    "    \"\"\" Given the training set, split the tensors by the class label. \"\"\"\n",
    "    n_classes = 10\n",
    "    if n_classes % n_splits != 0:\n",
    "        print(\"n_classes should be a multiple of the number of splits!\")\n",
    "        raise NotImplemented\n",
    "    class_for_split = n_classes // n_splits\n",
    "    mnist_train_test = [[],[]]  # train and test\n",
    "    for id, data_set in enumerate([(train_x, train_y), (test_x, test_y)]):\n",
    "        for i in range(n_splits):\n",
    "            start = i * class_for_split\n",
    "            end = (i + 1) * class_for_split\n",
    "            split_idxs = np.where(np.logical_and(data_set[1] >= start, data_set[1] < end))[0]\n",
    "            mnist_train_test[id].append((data_set[0][split_idxs], data_set[1][split_idxs]))\n",
    "    return mnist_train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "89m-P1b_iBF9"
   },
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y = mnist.load()\n",
    "splitmnist = split_mnist(train_x, train_y, test_x, test_y, n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9i8D6_dioCYf",
    "outputId": "3c7e6c0b-a90b-4ed3-e6ac-31597d0c7349"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train & test splits for task 0: \n",
      "(12665, 1, 28, 28)\n",
      "(12665,)\n",
      "0 1\n",
      "train & test splits for task 1: \n",
      "(12089, 1, 28, 28)\n",
      "(12089,)\n",
      "2 3\n",
      "train & test splits for task 2: \n",
      "(11263, 1, 28, 28)\n",
      "(11263,)\n",
      "4 5\n",
      "train & test splits for task 3: \n",
      "(12183, 1, 28, 28)\n",
      "(12183,)\n",
      "6 7\n",
      "train & test splits for task 4: \n",
      "(11800, 1, 28, 28)\n",
      "(11800,)\n",
      "8 9\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    train_split_x, train_split_y = splitmnist[0][i]\n",
    "    test_split_x, tests_split_y = splitmnist[1][i]\n",
    "    print(\"train & test splits for task {}: \".format(i))\n",
    "    print(train_split_x.shape)\n",
    "    print(train_split_y.shape)\n",
    "    print(min(train_split_y), max(train_split_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1UBJxBqExQJy"
   },
   "source": [
    "**Exercises / Questions to explore**:\n",
    "\n",
    "- Plot a few sample data belonging to each experience.\n",
    "- Is **SplitMNIST** harder than **PermutedMNIST**?\n",
    "- Is it more realistic? Why?\n",
    "- Compute the results of the introduced baselines. What can you deduce from the plots?\n",
    "\n",
    "Some tips here: https://arxiv.org/pdf/1904.07734.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OS9gHzZM7HQr"
   },
   "source": [
    "**Copyright (c) 2021. Continual AI. All rights reserved.**\n",
    "\n",
    "See the accompanying LICENSE file in the GitHub repository for terms. \n",
    "\n",
    "*Date: 15-11-2021                                                             \n",
    "Author: Vincenzo Lomonaco                                                    \n",
    "E-mail: contact@continualai.org                                           \n",
    "Website: continualai.org*                                               "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "permuted_and_split_mnist.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
