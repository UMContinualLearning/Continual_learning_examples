{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nf_dmKrevc8n"
   },
   "source": [
    "# Understanding Forgetting in Neural Networks with One Neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4rRMckxv56C"
   },
   "source": [
    "In the past few years a number of papers have shown the impact of forgetting in neural networks when learning continually over time and without access to previously encountered data. However, many of the examples used to describe the phenomenon are quite complex and involve thousands if not million of parameters.\n",
    "\n",
    "In this brief notebook I'll try to make the simplest possible example of catastrophic forgetting in neural networks, with just **one neuron** and **two paramerers** (a weight and a bias term), i.e. using a linear regression.\n",
    "\n",
    "We will build on top of the \"*House Prices*\" dataset and the example used in the famous Coursera \"*Machine Learning*\" course by Andrew Ng and we will:\n",
    "\n",
    "1. Build a continual learning setting\n",
    "2. Show ideal trained parameters for the linear regression model\n",
    "3. Show the impact of forgetting when changing the data distribution\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "gLd02AK3-Cvx",
    "outputId": "ef187806-3177-4154-d5cb-5d986887ed79"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib import rc\n",
    "import unittest\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.5)\n",
    "rcParams['figure.figsize'] = 14, 8\n",
    "rcParams['animation.embed_limit'] = 2**128\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "id": "lsaJ3jzm-NqT",
    "outputId": "fce17c0c-b666-4692-a5ef-5d2308404109"
   },
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/Data-Science-FMI/ml-from-scratch-2019/master/data/house_prices_train.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ao13HLI0CaQ"
   },
   "source": [
    "This is the summary of the dataset we are going to use and some of his main attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "id": "HXbItNAp-Sl4",
    "outputId": "82ff6bfc-e152-4c9a-b422-fd8bd1b63832"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('house_prices_train.csv')\n",
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182
    },
    "id": "f474iZGU-jQi",
    "outputId": "2559fd4f-6991-4f94-f23f-e2d563a232f7"
   },
   "outputs": [],
   "source": [
    "df_train['SalePrice'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "id": "Zi9XML6j-mgD",
    "outputId": "8f4b3cd5-2dec-48c2-9275-56357cc24872"
   },
   "outputs": [],
   "source": [
    "sns.distplot(df_train['SalePrice']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SgsbMXbV0X3b"
   },
   "source": [
    "Below we can see how the Living Room square feets nicely correlates with the House sale price:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "id": "BmDRbK-f-q5-",
    "outputId": "a25a98bf-c8f8-4bd2-fc71-5646d2e34aa4"
   },
   "outputs": [],
   "source": [
    "var = 'GrLivArea'\n",
    "data = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\n",
    "data.plot.scatter(x=var, y='SalePrice', ylim=(0,800000), s=32);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yWF861Pb0VSH"
   },
   "source": [
    "Now, to create a continual learning setting we split the dataset in two: we assume for example that the data comes in two distinct batch, the first one in houses build before 2000 and the second of the more recent houses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RJSW-VkS-wgL"
   },
   "outputs": [],
   "source": [
    "df_new = df_train[df_train.YearBuilt > 2000]\n",
    "df_old = df_train[df_train.YearBuilt <= 2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "id": "iCoZWqk0BkqP",
    "outputId": "21394e3a-0884-42e0-dd65-15270d3e3286"
   },
   "outputs": [],
   "source": [
    "df_new.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "id": "dGVpIHlaBoAK",
    "outputId": "4b4236c3-a418-42e0-8651-aa87cfd57c8b"
   },
   "outputs": [],
   "source": [
    "df_old.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "id": "wA1JABtcAVUg",
    "outputId": "efe93d0d-9f41-473b-b963-b8d0570b21ff"
   },
   "outputs": [],
   "source": [
    "var = 'GrLivArea'\n",
    "data = pd.concat([df_train['SalePrice'], df_new[var]], axis=1)\n",
    "data.plot.scatter(x=var, y='SalePrice', ylim=(0,800000), s=32, color=\"orange\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "id": "GlkXZ6UuAp0m",
    "outputId": "32518102-6292-4085-f569-ee3b9e828b1b"
   },
   "outputs": [],
   "source": [
    "var = 'GrLivArea'\n",
    "data = pd.concat([df_train['SalePrice'], df_old[var]], axis=1)\n",
    "data.plot.scatter(x=var, y='SalePrice', ylim=(0,800000), s=32, color=\"blue\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zw3oXb5n1cdh"
   },
   "source": [
    "It makes sense that on average more recent house are sold at higher prices.\n",
    "Let us know train the linear regression model our single neuron on the entire training set to get the best params:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "EeuZUP6oBvxE",
    "outputId": "46b751fb-a7d1-4e33-f50a-ab0a4175b387"
   },
   "outputs": [],
   "source": [
    "cumul_x = df_train['GrLivArea']\n",
    "cumul_y = df_train['SalePrice']\n",
    "\n",
    "# x = (x - x.mean()) / x.std()\n",
    "cumul_x = np.c_[np.ones(cumul_x.shape[0]), cumul_x] \n",
    "\n",
    "cumul_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vzwLwYbWB8QQ"
   },
   "outputs": [],
   "source": [
    "def loss(h, y):\n",
    "  sq_error = (h - y)**2\n",
    "  n = len(y)\n",
    "  return 1.0 / (2*n) * sq_error.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EcUHRmkzB_ja"
   },
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "\n",
    "  def __init__(self):\n",
    "    \n",
    "    self._W = np.zeros(2)\n",
    "    self._cost_history = []\n",
    "    self._w_history = [self._W]\n",
    "  \n",
    "  def predict(self, X):\n",
    "\n",
    "    return np.dot(X, self._W)\n",
    "  \n",
    "  def _gradient_descent_step(self, X, targets, lr):\n",
    "\n",
    "    predictions = self.predict(X)\n",
    "    \n",
    "    error = predictions - targets\n",
    "    gradient = np.dot(X.T,  error) / len(X)\n",
    "\n",
    "    self._W -= lr * gradient\n",
    "      \n",
    "  def fit(self, X, y, n_iter=100000, lr=0.01):\n",
    "\n",
    "    for i in range(n_iter):\n",
    "      \n",
    "        prediction = self.predict(X)\n",
    "        cost = loss(prediction, y)\n",
    "        \n",
    "        self._cost_history.append(cost)\n",
    "        \n",
    "        self._gradient_descent_step(X, y, lr)\n",
    "        \n",
    "        self._w_history.append(self._W.copy())\n",
    "        \n",
    "    return self\n",
    "      \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "MNzRv17VCCT1",
    "outputId": "7463da11-b9ef-4304-86ab-0a0038d7bf85"
   },
   "outputs": [],
   "source": [
    "cumul_clf = LinearRegression()\n",
    "cumul_clf.fit(cumul_x, cumul_y, n_iter=150, lr=1e-7)\n",
    "\n",
    "cumul_clf._W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "id": "wCZC0SBqCKXG",
    "outputId": "ff7ece07-65a6-4fd4-f309-55ce50dfa8a1"
   },
   "outputs": [],
   "source": [
    "plt.title('Cost Function J')\n",
    "plt.xlabel('No. of iterations')\n",
    "plt.ylabel('Cost')\n",
    "plt.plot(cumul_clf._cost_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ILa_I0sZCQ5P"
   },
   "outputs": [],
   "source": [
    "#Animation\n",
    "def animate(clf, set_x, set_y, frames=150):\n",
    "    #Set the plot up,\n",
    "    fig = plt.figure()\n",
    "    ax = plt.axes()\n",
    "    plt.title('Sale Price vs Living Area')\n",
    "    plt.xlabel('Living Area in square feet')\n",
    "    plt.ylabel('Sale Price ($)')\n",
    "    if len(set_x) == 1:\n",
    "        plt.scatter(set_x[0][:,1], set_y[0])\n",
    "    else:\n",
    "        plt.scatter(set_x[0][:,1], set_y[0], color=\"blue\")\n",
    "        plt.scatter(set_x[1][:,1], set_y[1], color=\"orange\")\n",
    "    line, = ax.plot([], [], lw=2, color='red')\n",
    "    annotation = ax.text(200, 700000, '')\n",
    "    # optimal\n",
    "    x = np.linspace(0, 7000, 1000)\n",
    "    y = cumul_clf._W[1]*x + cumul_clf._W[0]\n",
    "    ax.plot(x, y, 'g--')\n",
    "    annotation.set_animated(True)\n",
    "    plt.close()\n",
    "\n",
    "    #Generate the animation data,\n",
    "    def init():\n",
    "        line.set_data([], [])\n",
    "        annotation.set_text('')\n",
    "        return line, annotation\n",
    "\n",
    "    # animation function.  This is called sequentially\n",
    "    def animate(i):\n",
    "        # x = np.linspace(-5, 20, 1000)\n",
    "        x = np.linspace(0, 7000, 1000)\n",
    "        y = clf._w_history[i][1]*x + clf._w_history[i][0]\n",
    "        line.set_data(x, y)\n",
    "        annotation.set_text(\n",
    "            'Cost = %.2f e10\\nWeight: %.2f\\nBias: %.2f' % \n",
    "            (clf._cost_history[i]/1e10, clf._w_history[i][1],\n",
    "             clf._w_history[i][0]))\n",
    "        return line, annotation\n",
    "\n",
    "    anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                                frames=frames, interval=10, blit=True)\n",
    "\n",
    "    rc('animation', html='jshtml')\n",
    "\n",
    "    return anim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 396
    },
    "id": "kfKjDrkkLsOv",
    "outputId": "8336bd12-2703-458d-d597-d6b8f287d824"
   },
   "outputs": [],
   "source": [
    "anim = animate(cumul_clf, [cumul_x], [cumul_y])\n",
    "anim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KFr6FSxh2vuc"
   },
   "source": [
    "Ok so the best parameters for the job are weight: 9.94290254e-02 and bias:1.18069042e+02. This will appear as a green dashed line in the plot. Let's now move the continual learning scenario.\n",
    "\n",
    "In this case we will start with the first batch of data (that is the batch with all the old houses data) and than, with the optimal parameters computed at this step we will try to model also the data of the second batch (with the newest houses data).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "nETr8EHPGaon",
    "outputId": "f04b28eb-1661-4048-ad7e-de193941817a"
   },
   "outputs": [],
   "source": [
    "x_old = df_old['GrLivArea']\n",
    "y_old = df_old['SalePrice']\n",
    "\n",
    "x_old = np.c_[np.ones(x_old.shape[0]), x_old] \n",
    "\n",
    "x_old.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "Cz4jy4RyHxO7",
    "outputId": "17958d5e-8ddd-4483-cba6-394b08fb97a9"
   },
   "outputs": [],
   "source": [
    "x_new = df_new['GrLivArea']\n",
    "y_new = df_new['SalePrice']\n",
    "\n",
    "x_new = np.c_[np.ones(x_new.shape[0]), x_new] \n",
    "\n",
    "x_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "vK2LAMa7GxJ7",
    "outputId": "c1982655-0df3-4d44-f7e1-8216b50dc7f7"
   },
   "outputs": [],
   "source": [
    "cl_clf = LinearRegression()\n",
    "cl_clf.fit(x_old, y_old, n_iter=150, lr=1e-7)\n",
    "\n",
    "cl_clf._W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 396
    },
    "id": "IXnxe8VrG-4x",
    "outputId": "d44b9a62-2c22-43b2-ab86-1be3f9fc187a"
   },
   "outputs": [],
   "source": [
    "anim = animate(cl_clf, [x_old, x_new], [y_old, y_new])\n",
    "anim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ga4FQuFA4GOm"
   },
   "source": [
    "In the plot above we can see that the model is only fitting the old houses data as we would expect! Let us know see what happens if we finetune the model on the newest houses batch!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "mdlKIIWNH28u",
    "outputId": "bbd2ebe1-467a-4717-aa07-670a7253bc90"
   },
   "outputs": [],
   "source": [
    "# cl_clf = LinearRegression()\n",
    "cl_clf.fit(x_new, y_new, n_iter=150, lr=1e-7)\n",
    "\n",
    "cl_clf._W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "id": "t4y-ZpKTNgBs",
    "outputId": "1eb389de-ae10-42d5-8edd-56ca3be6fbe3"
   },
   "outputs": [],
   "source": [
    "plt.title('Cost Function J')\n",
    "plt.xlabel('No. of iterations')\n",
    "plt.ylabel('Cost')\n",
    "plt.plot(cl_clf._cost_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 396
    },
    "id": "7U1jTkC2H82p",
    "outputId": "48ba1bc1-31d2-4e77-eb4b-1225edc5e7da"
   },
   "outputs": [],
   "source": [
    "anim = animate(cl_clf, [x_old, x_new], [y_old, y_new], frames=300)\n",
    "anim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9sOOd-kq42hC"
   },
   "source": [
    "So what we can see from the plot above is that even though we are starting from the best possible solution of the previous step our weight and bias parameters are somehow overwritten only to suit the new data distibution of the newest houses. \n",
    "\n",
    "Here, we are essetially \"*forgetting*\" how to correctly predict the price of houses build before 2000 just to better predict the price of the houses built after 2000, even though (here's the point) a better and general parametrization **do exist** and would have reduced the total prediction error.\n",
    "\n",
    "How can we efficiently learn that best parametrization over time and without accessing previously encontered data is one of the main focus of Continual Learning."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "simplest_forgetting_house",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
