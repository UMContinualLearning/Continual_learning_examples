{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71dede7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# EWC: \n",
    "# \"Overcoming catastrophic forgetting in neural networks\" by Kirkpatrick et. al. (2017).\n",
    "# https://www.pnas.org/content/114/13/3521\n",
    "# \"\"\"\n",
    "###################################################################################################################\n",
    "# \"\"\"\"\n",
    "# \"Learning without Forgetting\" by Li et. al. (2016).\n",
    "# http://arxiv.org/abs/1606.09282\n",
    "# Since experimental setup of the paper is quite outdated and not\n",
    "# easily reproducible, this experiment is based on\n",
    "# \"Three scenarios for continual learning\" by van de Ven et. al. (2018).\n",
    "# https://arxiv.org/pdf/1904.07734.pdf\n",
    "\n",
    "# Please, note that the performance of LwF on Permuted MNIST is below the one achieved\n",
    "# by Naive with the same configuration. This is compatible with the results presented\n",
    "# by van de Ven et. al. (2018).\n",
    "# \"\"\"\n",
    "###################################################################################################################\n",
    "# \"\"\"\n",
    "# \"Continual Learning Through Synaptic Intelligence\" by Zenke et. al. (2017).\n",
    "# http://proceedings.mlr.press/v70/zenke17a.html\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b23bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install avalanche-lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae685d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import avalanche as avl\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam, SGD\n",
    "# from avalanche.evaluation import metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210f7d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def set_seed(seed):\n",
    "    if seed is None:\n",
    "        return\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.enabled = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "def create_default_args(args_dict, additional_args=None):\n",
    "    args = SimpleNamespace()\n",
    "    for k, v in args_dict.items():\n",
    "        args.__dict__[k] = v\n",
    "    if additional_args is not None:\n",
    "        for k, v in additional_args.items():\n",
    "            args.__dict__[k] = v\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdb802f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(args):\n",
    "    set_seed(args.seed)\n",
    "    device = torch.device(f\"cuda:0\"\n",
    "                          if torch.cuda.is_available() \n",
    "                          else \"cpu\")\n",
    "    \n",
    "    if args.benchmark == 'pmnist':\n",
    "        benchmark = avl.benchmarks.PermutedMNIST(10)\n",
    "        num_classes = 10\n",
    "        input_size = 784\n",
    "    \n",
    "    elif args.benchmark == 'smnist':\n",
    "        benchmark = avl.benchmarks.SplitMNIST(\n",
    "            n_experiences=5, # continual learning; 5 experiences, 2 digits/classes per experience\n",
    "            return_task_id=args.multitask, # set to True for multi-task experiments\n",
    "        )\n",
    "        num_classes = 10\n",
    "        input_size = 784\n",
    "    # add other benchmarks as needed\n",
    "    \n",
    "    if args.model == 'mlp':\n",
    "        model = avl.models.SimpleMLP(\n",
    "            num_classes=num_classes, \n",
    "            input_size=input_size, \n",
    "            hidden_size=args.hidden_size, \n",
    "            hidden_layers=args.hidden_layers, \n",
    "            drop_rate=args.dropout\n",
    "        )\n",
    "    # add other models as needed\n",
    "        \n",
    "    if args.multitask: \n",
    "        model = avl.models.as_multitask(model, 'classifier')\n",
    "    \n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "    interactive_logger = avl.logging.InteractiveLogger()\n",
    "\n",
    "    evaluation_plugin = avl.training.plugins.EvaluationPlugin(\n",
    "        avl.evaluation.metrics.accuracy_metrics(epoch=True, experience=True, stream=True),\n",
    "        avl.evaluation.metrics.forgetting_metrics(experience=True, stream=True),\n",
    "#         avl.evaluation.metrics.bwt_metrics(experience=True, stream=True),\n",
    "#         avl.evaluation.metrics.ram_usage_metrics(every=1, minibatch=True, epoch=True, experience=True, stream=True),\n",
    "        avl.evaluation.metrics.timing_metrics(minibatch=False, epoch=True, epoch_running=True, experience=True, stream=True),\n",
    "        loggers=[interactive_logger])\n",
    "    # add other evaluation metrics as needed\n",
    "    \n",
    "    if args.strategy == 'ewc':\n",
    "        cl_strategy = avl.training.EWC(\n",
    "            model, \n",
    "            SGD(model.parameters(), lr=args.learning_rate), \n",
    "            criterion,\n",
    "            ewc_lambda=args.ewc_lambda, \n",
    "            mode=args.ewc_mode, \n",
    "            decay_factor=args.ewc_decay,\n",
    "            train_mb_size=args.train_mb_size, \n",
    "            train_epochs=args.epochs, \n",
    "            eval_mb_size=args.eval_mb_size,\n",
    "            device=device, \n",
    "            evaluator=evaluation_plugin\n",
    "        )\n",
    "    \n",
    "    elif args.strategy == 'lwf':\n",
    "        cl_strategy = LwFCEPenalty(\n",
    "            model, \n",
    "            Adam(model.parameters(), lr=args.learning_rate), \n",
    "            criterion,\n",
    "            alpha=args.lwf_alpha,\n",
    "            temperature=args.lwf_temperature,\n",
    "            train_mb_size=args.train_mb_size, \n",
    "            train_epochs=args.epochs, \n",
    "            eval_mb_size=args.eval_mb_size,\n",
    "            device=device, \n",
    "            evaluator=evaluation_plugin\n",
    "        )\n",
    "        \n",
    "    elif args.strategy == 'si':\n",
    "        cl_strategy = avl.training.SynapticIntelligence(\n",
    "            model, \n",
    "            Adam(model.parameters(), lr=args.learning_rate), \n",
    "            criterion,\n",
    "            si_lambda=args.si_lambda, \n",
    "            eps=args.si_eps,\n",
    "            train_mb_size=args.train_mb_size, \n",
    "            train_epochs=args.epochs, \n",
    "            eval_mb_size=args.eval_mb_size,\n",
    "            device=device, \n",
    "            evaluator=evaluation_plugin\n",
    "        )\n",
    "    # add other learning strategies as needed\n",
    "\n",
    "    print(\"Starting experiment...\")\n",
    "    results = []\n",
    "    for experience in benchmark.train_stream:\n",
    "        print(\"Start training on experience \", experience.current_experience)\n",
    "        cl_strategy.train(experience)\n",
    "        print(\"Computing accuracy on the test set\")\n",
    "        results += [cl_strategy.eval(benchmark.test_stream[:])]\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e26b393",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64ab6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EWC experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1825205b",
   "metadata": {},
   "outputs": [],
   "source": [
    "args_ewc_pmnist = create_default_args({\n",
    "    'benchmark': 'pmnist',\n",
    "    'multitask': False,\n",
    "    \n",
    "    'model': 'mlp',\n",
    "    'learning_rate': 0.001, \n",
    "    'train_mb_size': 128,\n",
    "    'eval_mb_size': 128,\n",
    "    'hidden_size': 500,\n",
    "    'hidden_layers': 2, \n",
    "    'epochs': 1, \n",
    "    'dropout': 0,\n",
    "    'seed': 0,\n",
    "    \n",
    "    'strategy': 'ewc',\n",
    "    'ewc_lambda': 1, \n",
    "    'ewc_mode': 'separate', \n",
    "#     'ewc_mode': 'online', \n",
    "    'ewc_decay': None,\n",
    "})\n",
    "results_ewc_pmnist = run(args_ewc_pmnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54309ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "args_ewc_smnist = create_default_args({\n",
    "    'benchmark': 'smnist',\n",
    "    'multitask': True,\n",
    "    \n",
    "    'model': 'mlp',\n",
    "    'learning_rate': 0.001, \n",
    "    'train_mb_size': 128,\n",
    "    'eval_mb_size': 128,\n",
    "    'hidden_size': 500,\n",
    "    'hidden_layers': 2, \n",
    "    'epochs': 1, \n",
    "    'dropout': 0,\n",
    "    'seed': 0,\n",
    "    \n",
    "    'strategy': 'ewc',\n",
    "    'ewc_lambda': 1, \n",
    "    'ewc_mode': 'separate', \n",
    "#     'ewc_mode': 'online', \n",
    "    'ewc_decay': None,\n",
    "})\n",
    "results_ewc_smnist = run(args_ewc_smnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0430252f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a7d41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LWF experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483cc023",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LwFCEPenalty(avl.training.LwF):\n",
    "    \"\"\"This wrapper around LwF computes the total loss\n",
    "    by diminishing the cross-entropy contribution over time,\n",
    "    as per the paper\n",
    "    \"Three scenarios for continual learning\" by van de Ven et. al. (2018).\n",
    "    https://arxiv.org/pdf/1904.07734.pdf\n",
    "    The loss is L_tot = (1/n_exp_so_far) * L_cross_entropy +\n",
    "                        alpha[current_exp] * L_distillation\n",
    "    \"\"\"\n",
    "    def _before_backward(self, **kwargs):\n",
    "        self.loss *= float(1/(self.clock.train_exp_counter+1))\n",
    "        super()._before_backward(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a217ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "args_lwf_pmnist = create_default_args({\n",
    "    'benchmark': 'pmnist',\n",
    "    'multitask': False,\n",
    "    \n",
    "    'model': 'mlp',\n",
    "    'learning_rate': 0.001, \n",
    "    'train_mb_size': 128,\n",
    "    'eval_mb_size': 128,\n",
    "    'hidden_size': 500,\n",
    "    'hidden_layers': 2, \n",
    "    'epochs': 1, \n",
    "    'dropout': 0,\n",
    "    'seed': 0,\n",
    "    \n",
    "    'strategy': 'lwf',\n",
    "    'lwf_alpha': [0.]+[1-(1./float(i)) for i in range(2, 11)], # Penalty hyperparameter for LwF. It can be either a list with \n",
    "        # multiple elements (one alpha per experience) or a list of one element (same alpha for all experiences).\n",
    "    'lwf_temperature': 2, # Temperature for softmax used in distillation\n",
    "})\n",
    "\n",
    "results_lwf_pmnist = run(args_lwf_pmnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128f0337",
   "metadata": {},
   "outputs": [],
   "source": [
    "args_lwf_smnist = create_default_args({\n",
    "    'benchmark': 'smnist',\n",
    "    'multitask': True,\n",
    "    \n",
    "    'model': 'mlp',\n",
    "    'learning_rate': 0.001, \n",
    "    'train_mb_size': 128,\n",
    "    'eval_mb_size': 128,\n",
    "    'hidden_size': 500,\n",
    "    'hidden_layers': 2, \n",
    "    'epochs': 1, \n",
    "    'dropout': 0,\n",
    "    'seed': 0,\n",
    "    \n",
    "    'strategy': 'lwf',\n",
    "    'lwf_alpha': [0.]+[1-(1./float(i)) for i in range(2, 6)], # Penalty hyperparameter for LwF. It can be either a list with \n",
    "        # multiple elements (one alpha per experience) or a list of one element (same alpha for all experiences).\n",
    "    'lwf_temperature': 2, # Temperature for softmax used in distillation\n",
    "})\n",
    "\n",
    "results_lwf_smnist = run(args_lwf_smnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0d7508",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42a1369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SI experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807d7332",
   "metadata": {},
   "outputs": [],
   "source": [
    "args_si_pmnist = create_default_args({\n",
    "    'benchmark': 'pmnist',\n",
    "    'multitask': False,\n",
    "    \n",
    "    'model': 'mlp',\n",
    "    'learning_rate': 0.001, \n",
    "    'train_mb_size': 128,\n",
    "    'eval_mb_size': 128,\n",
    "    'hidden_size': 500,\n",
    "    'hidden_layers': 2, \n",
    "    'epochs': 1, \n",
    "    'dropout': 0,\n",
    "    'seed': 0,\n",
    "    \n",
    "    'strategy': 'si',\n",
    "    'si_lambda': 0.1, \n",
    "    'si_eps': 0.1,     \n",
    "})\n",
    "\n",
    "results_si_pmnist = run(args_si_pmnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037a7735",
   "metadata": {},
   "outputs": [],
   "source": [
    "args_si_smnist = create_default_args({\n",
    "    'benchmark': 'smnist',\n",
    "    'multitask': True,\n",
    "    \n",
    "    'model': 'mlp',\n",
    "    'learning_rate': 0.001, \n",
    "    'train_mb_size': 128,\n",
    "    'eval_mb_size': 128,\n",
    "    'hidden_size': 500,\n",
    "    'hidden_layers': 2, \n",
    "    'epochs': 1, \n",
    "    'dropout': 0,\n",
    "    'seed': 0,\n",
    "    \n",
    "    'strategy': 'si',\n",
    "    'si_lambda': 0.1, \n",
    "    'si_eps': 0.1,     \n",
    "})\n",
    "\n",
    "results_si_smnist = run(args_si_smnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0359fe2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
