{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1437deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install avalanche-lib==0.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3db58b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import avalanche as avl\n",
    "import torch\n",
    "from avalanche.evaluation import metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5adab6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = avl.models.SimpleMLP(\n",
    "    input_size = 784, \n",
    "    hidden_size = 256,\n",
    "    hidden_layers = 2,\n",
    "    drop_rate = 0.5,\n",
    "    num_classes = 10\n",
    ")\n",
    "\n",
    "# model = avl.models.as_multitask(model, 'classifier') # convert the SimpleMLP model into a multi-task model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b26f0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = avl.benchmarks.SplitMNIST(\n",
    "    n_experiences=5,\n",
    "    return_task_id=False, # set to True for multi-task experiments\n",
    "    seed=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a244eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_logger = avl.logging.InteractiveLogger()\n",
    "\n",
    "evaluation_plugin = avl.training.plugins.EvaluationPlugin(\n",
    "    metrics.accuracy_metrics(experience=True),\n",
    "    metrics.forgetting_metrics(experience=True),\n",
    "    loggers=[interactive_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167a2206",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_strategy = avl.training.Naive(\n",
    "    model = model, \n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.001), \n",
    "    criterion = torch.nn.CrossEntropyLoss(),\n",
    "    train_mb_size = 128, \n",
    "    train_epochs = 1,\n",
    "    evaluator = evaluation_plugin)\n",
    "\n",
    "# cl_strategy = avl.training.Cumulative(\n",
    "#     model = model, \n",
    "#     optimizer = torch.optim.SGD(model.parameters(), lr=0.001), \n",
    "#     criterion = torch.nn.CrossEntropyLoss(),\n",
    "#     train_mb_size = 128, \n",
    "#     train_epochs = 1,\n",
    "#     evaluator = evaluation_plugin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4756b815",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for experience in benchmark.train_stream:\n",
    "    print(\"Current Experience: \", experience.current_experience)\n",
    "    cl_strategy.train(experience)\n",
    "    results += [cl_strategy.eval(benchmark.test_stream)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fd46e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829a215f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d54a59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73d4ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8663a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be50ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "acc0 = []\n",
    "acc1 = []\n",
    "acc2 = []\n",
    "acc3 = []\n",
    "acc4 = []\n",
    "\n",
    "for0 = []\n",
    "for1 = []\n",
    "for2 = []\n",
    "for3 = []\n",
    "\n",
    "for a in results:\n",
    "    for b in a:\n",
    "        c = b.split(\"/\")\n",
    "        if (c[0] == \"Top1_Acc_Exp\") and (c[-1]==\"Exp000\"):\n",
    "            acc0 += [a[b]]\n",
    "        elif (c[0] == \"Top1_Acc_Exp\") and (c[-1]==\"Exp001\"):\n",
    "            acc1 += [a[b]]\n",
    "        elif (c[0] == \"Top1_Acc_Exp\") and (c[-1]==\"Exp002\"):\n",
    "            acc2 += [a[b]]\n",
    "        elif (c[0] == \"Top1_Acc_Exp\") and (c[-1]==\"Exp003\"):\n",
    "            acc3 += [a[b]]\n",
    "        elif (c[0] == \"Top1_Acc_Exp\") and (c[-1]==\"Exp004\"):\n",
    "            acc4 += [a[b]]\n",
    "        elif (c[0] == \"ExperienceForgetting\") and (c[-1]==\"Exp000\"):\n",
    "            for0 += [a[b]]\n",
    "        elif (c[0] == \"ExperienceForgetting\") and (c[-1]==\"Exp001\"):\n",
    "            for1 += [a[b]]\n",
    "        elif (c[0] == \"ExperienceForgetting\") and (c[-1]==\"Exp002\"):\n",
    "            for2 += [a[b]]\n",
    "        elif (c[0] == \"ExperienceForgetting\") and (c[-1]==\"Exp003\"):\n",
    "            for3 += [a[b]]\n",
    "\n",
    "acc0 = np.array(acc0)\n",
    "acc1 = np.array(acc1)\n",
    "acc2 = np.array(acc2)\n",
    "acc3 = np.array(acc3)\n",
    "acc4 = np.array(acc4)\n",
    "for0 = np.array(for0)\n",
    "for1 = np.array(for1)\n",
    "for2 = np.array(for2)\n",
    "for3 = np.array(for3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0386acf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "while len(for0) < 5:\n",
    "    for0 = np.concatenate((np.zeros(1), for0))\n",
    "\n",
    "while len(for1) < 5:\n",
    "    for1 = np.concatenate((np.zeros(1), for1))\n",
    "\n",
    "while len(for2) < 5:\n",
    "    for2 = np.concatenate((np.zeros(1), for2))\n",
    "    \n",
    "while len(for3) < 5:\n",
    "    for3 = np.concatenate((np.zeros(1), for3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7267fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience = np.array(range(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc16bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "[plt.plot(experience, acc0, label='exp0'),\n",
    " plt.plot(experience, acc1, label='exp1'),\n",
    " plt.plot(experience, acc2, label='exp2'),\n",
    " plt.plot(experience, acc3, label='exp3'),\n",
    " plt.plot(experience, acc4, label='exp4'),\n",
    " plt.xlabel(\"training experience\"), \n",
    " plt.xticks([0,1,2,3,4]),\n",
    " plt.ylabel(\"experience testing accuracy\"),\n",
    " plt.figlegend(),\n",
    " plt.title(\"Testing Accuracy\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2797d1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "[plt.plot(experience, for0, label='exp0'),\n",
    " plt.plot(experience, for1, label='exp1'),\n",
    " plt.plot(experience, for2, label='exp2'),\n",
    " plt.plot(experience, for3, label='exp3'),\n",
    " plt.xlabel(\"training experience\"), \n",
    " plt.xticks([0,1,2,3,4]),\n",
    " plt.ylabel(\"experience forgetting\"),\n",
    " plt.figlegend(),\n",
    " plt.title(\"Forgetting score\")\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
